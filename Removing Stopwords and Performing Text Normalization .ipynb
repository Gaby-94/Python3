{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Stopwords?\n",
    "\n",
    "\n",
    "Stopwords are the most common words in any natural language. For the purpose of analyzing text data and building NLP models, these stopwords might not add much value to the meaning of the document.\n",
    "\n",
    "    Generally, the most common words used in a text are “the”, “is”, “in”, “for”, “where”, “when”, “to”, “at” etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a about after all also always am an and any are at be been being but by came can cant come \n",
    "could did didn't do does doesn't doing don't else for from get give goes going had happen \n",
    "has have having how i if ill i'm in into is isn't it its i've just keep let like made make \n",
    "many may me mean more most much no not now of only or our really say see some something \n",
    "take tell than that the their them then they thing this to try up us use used uses very \n",
    "want was way we what when where which who why will with without wont you your youre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Should we Remove Stopwords?\n",
    "\n",
    "I’ve summarized this into two parts: when we can remove stopwords and when we should avoid doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove stopwords while performing the following tasks:\n",
    "\n",
    "    Text Classification\n",
    "        Spam Filtering\n",
    "        Language Classification\n",
    "        Genre Classification\n",
    "    Caption Generation\n",
    "    Auto-Tag Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid Stopword Removal\n",
    "\n",
    "\n",
    "    Machine Translation\n",
    "    Language Modeling\n",
    "    Text Summarization\n",
    "    Question-Answering problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Methods to Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stopword Removal using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the below code to see the list of stopwords in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is to remove stop words from sentence using nltk\n",
    "# Created by - ANALYTICS VIDHYA\n",
    "\n",
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentence\n",
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of stop words\n",
    "#stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens of words  \n",
    "#word_tokens = word_tokenize(text) \n",
    "    \n",
    "#filtered_sentence = [] \n",
    "  \n",
    "#for w in word_tokens: \n",
    "    #if w not in stop_words: \n",
    "        #filtered_sentence.append(w) \n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\n\\nOriginal Sentence \\n\\n\")\n",
    "#print(\" \".join(word_tokens)) \n",
    "\n",
    "#print(\"\\n\\nFiltered Sentence \\n\\n\")\n",
    "#print(\" \".join(filtered_sentence)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list we obtained after tokenization:\n",
    "\n",
    "He determined to drop his litigation with the monastry, and relinguish his claims to the \n",
    "wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights\n",
    "had become much less valuable, and he had indeed the vaguest idea where the wood and river\n",
    " in question were"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the list after removing stopwords:\n",
    "\n",
    "He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He \n",
    "ready becuase rights become much less valuable, indeed vaguest idea wood river question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how you can remove stopwords using spaCy in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = English()\n",
    "\n",
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "#my_doc = nlp(text)\n",
    "\n",
    "# Create list of word tokens\n",
    "#token_list = []\n",
    "#for token in my_doc:\n",
    "    #token_list.append(token.text)\n",
    "\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Create list of word tokens after removing stopwords\n",
    "#filtered_sentence =[] \n",
    "\n",
    "#for word in token_list:\n",
    "    #lexeme = nlp.vocab[word]\n",
    "    #if lexeme.is_stop == False:\n",
    "        #filtered_sentence.append(word) \n",
    "#print(token_list)\n",
    "#print(filtered_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list we obtained after tokenization:\n",
    "\n",
    "He determined to drop his litigation with the monastry and relinguish his claims to the \n",
    "wood-cuting and \\n fishery rihgts at once. He was the more ready to do this becuase the \n",
    "rights had become much less valuable, and he had \\n indeed the vaguest idea where the wood\n",
    " and river in question were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the list after removing stopwords:\n",
    "\n",
    "determined drop litigation monastry, relinguish claims wood-cuting \\n fishery rihgts. ready\n",
    "becuase rights become valuable, \\n vaguest idea wood river question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stopword Removal using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is to remove stop words using gensim\n",
    "# Created by - ANALYTICS VIDHYA\n",
    "#from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# pass the sentence in the remove_stopwords function\n",
    "#result = remove_stopwords(\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, \n",
    "#and he had indeed the vaguest idea where the wood and river in question were.\"\"\")\n",
    "\n",
    "#print('\\n\\n Filtered Sentence \\n\\n')\n",
    "#print(result)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts once.\n",
    "He ready becuase rights valuable, vaguest idea wood river question were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are Stemming and Lemmatization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization is simply normalization of words, which means reducing a word to its root form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first understand stemming:\n",
    "\n",
    "    Stemming is a text normalization technique that cuts off the end or beginning of a word by taking into account a list of common prefixes or suffixes that could be found in that word\n",
    "    It is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization, on the other hand, is an organized & step-by-step procedure of obtaining the root form of the word. It makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods to Perform Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Normalization using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "#fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "#indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "#stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "#word_tokens = word_tokenize(text) \n",
    "    \n",
    "#filtered_sentence = [] \n",
    "  \n",
    "#for w in word_tokens: \n",
    "    #if w not in stop_words: \n",
    "        #filtered_sentence.append(w) \n",
    "\n",
    "#Stem_words = []\n",
    "#ps =PorterStemmer()\n",
    "#for w in filtered_sentence:\n",
    "    #rootWord=ps.stem(w)\n",
    "    #Stem_words.append(rootWord)\n",
    "#print(filtered_sentence)\n",
    "#print(Stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He \n",
    "ready becuase rights become much less valuable, indeed vaguest idea wood river question.\n",
    "\n",
    "He determin drop litig monastri, relinguish claim wood-cut fisheri rihgt. He readi becuas\n",
    "right become much less valuabl, inde vaguest idea wood river question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "#import nltk\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#set(stopwords.words('english'))\n",
    "\n",
    "#text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "#fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "#indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "#stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "#word_tokens = word_tokenize(text) \n",
    "    \n",
    "#filtered_sentence = [] \n",
    "  \n",
    "#for w in word_tokens: \n",
    "    #if w not in stop_words: \n",
    "        #filtered_sentence.append(w) \n",
    "#print(filtered_sentence) \n",
    "\n",
    "#lemma_word = []\n",
    "#import nltk\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#for w in filtered_sentence:\n",
    "    #word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
    "    #word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
    "    #word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
    "    #lemma_word.append(word3)\n",
    "#print(lemma_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts. He \n",
    "ready becuase rights become much less valuable, indeed vaguest idea wood river question.\n",
    "\n",
    "He determined drop litigation monastry, relinguish claim wood-cuting fishery rihgts. He \n",
    "ready becuase right become much le valuable, indeed vaguest idea wood river question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Normalization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to download the english model with \"python -m spacy download en\"\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc = nlp(u\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\")\n",
    "\n",
    "lemma_word1 = [] \n",
    "for token in doc:\n",
    "    lemma_word1.append(token.lemma_)\n",
    "lemma_word1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RON- determine to drop -PRON- litigation with the monastry, and relinguish -PRON- claim\n",
    "to the wood-cuting and \\n fishery rihgts at once. -PRON- be the more ready to do this \n",
    "becuase the right have become much less valuable, and -PRON- have \\n indeed the vague idea\n",
    "where the wood and river in question be.\n",
    "\n",
    "Here -PRON- is the notation for pronoun which could easily be removed using regular expressions. The benefit of spaCy is that we do not have to pass any pos parameter to perform lemmatization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Normalization using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a Python library especially made for preprocessing text data. It is based on the NLTK library. We can use TextBlob to perform lemmatization. However, there’s no module for stemming in TextBlob."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let’s see how to perform lemmatization using TextBlob in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob lib import Word method \n",
    "#from textblob import Word \n",
    "\n",
    "#text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "#fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "#indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "#lem = []\n",
    "#for i in text.split():\n",
    "    #word1 = Word(i).lemmatize(\"n\")\n",
    "    #word2 = Word(word1).lemmatize(\"v\")\n",
    "    #word3 = Word(word2).lemmatize(\"a\")\n",
    "    #lem.append(Word(word3).lemmatize())\n",
    "#print(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He determine to drop his litigation with the monastry, and relinguish his claim to the \n",
    "wood-cuting and fishery rihgts at once. He wa the more ready to do this becuase the right\n",
    "have become much le valuable, and he have indeed the vague idea where the wood and river\n",
    "in question were."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords play an important role in problems like sentiment analysis, question answering systems, etc. That’s why removing stopwords can potentially affect our model’s accuracy drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
