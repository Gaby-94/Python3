{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Machine learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comment ameliorer et deploier un projet de Machine Learning\n",
        "# **How to improve and depoiement your Machine Learning project**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZXaE7KM8oMLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Work   : Chercher des donnees / search data set\n",
        "        - kaggle \n",
        "        - Machine learning repository\n",
        "        - zindi \n",
        "        - autres sources de donnees\n",
        "\n",
        "2. Work : Comprendre et identifier le probleme  et les sources de donnees \n",
        "\n",
        "3. Work : Deployer votre modele\n",
        "\n"
      ],
      "metadata": {
        "id": "6R2Vjm8Xp1la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 1. Comprendre et identifier le problème du métier "
      ],
      "metadata": {
        "id": "rvOc-rspggTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La première phase de tout projet de machine learning consiste à:\n",
        "  \n",
        "\n",
        "1.   comprendre les besoins des métiers.\n",
        "2.   Comprendre les problématiques\n",
        "3.   Comprendre  les objectifs et les besoins\n",
        "\n",
        "\n",
        "\n",
        "✅\n",
        "*** Le but est de traduire cette connaissance en une définition mathématique appropriée du problème pour faire du machine learning, et de concevoir un plan préliminaire pour atteindre ces objectifs.:***\n"
      ],
      "metadata": {
        "id": "6IM6Y_m3glB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 2. Comprendre et identifier les données"
      ],
      "metadata": {
        "id": "u1UgiYXjg76d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    1. Définir  les sources des données nécessaires à l’entraînement du modèle ?\n",
        "    2. Déterminer le volume de données  nécessaire pour ce projet de machine learning ?\n",
        "    3.  Déterminer  la quantité et la qualité actuelles des jeux de données destinés à l’entraînement ?\n",
        "    4. Comment seront réparties les données entre l’ensemble de test et l’ensemble pour l’entraînement ?\n",
        "    5. Réfléchir sur les moyens financiers \n",
        "   \n"
      ],
      "metadata": {
        "id": "Z7g0rrMGhMrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3. Collecter et préparer les données"
      ],
      "metadata": {
        "id": "K2VTWuGVhO0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    1. Recueillir les données auprès des différentes sources.\n",
        "    2. Normaliser les formats des différentes données.\n",
        "    3. Remplacer les données incorrectes.\n",
        "    4. Améliorer et augmenter les données.\n",
        "   \n",
        "    5. Améliorer les données avec des sources tierces.\n",
        "    \n",
        "    6. Supprimer les informations superflues et les doublons.\n",
        "    7. Supprimer les données non pertinentes pour l’entraînement pour améliorer les résultats.\n",
        "    8. Réduire autant que possible le bruit et lever les ambiguïtés\n",
        "    9. Contrôler s’il faut anonymiser certaines données.\n",
        "    10. Normaliser ou standardiser les données pour qu’elles entrent dans les intervalles attendus (feature scaling)\n",
        "    11. Sélectionnez des attributs (feature engineering) qui identifient les dimensions les plus importantes \n",
        "    12.  réduisez les dimensions en utilisant diverses techniques.\n",
        "    13. Séparer les données en trois ensembles pour l’entraînement, le test et la validation.\n"
      ],
      "metadata": {
        "id": "IZgh6CY_hTcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 1 : Pre-processing (last date Mardi )"
      ],
      "metadata": {
        "id": "ViRw5_bSyt2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('mydata.csv')\n",
        "# To Do \n",
        "# 1. check missing data \n",
        "# 1.1. imputation des donnees si possible\n",
        "# 1.2. si c'est pas  possible de faire l'imputation je supprime \n",
        "\n",
        "# 2. Check extremes values  et faire le necessaire \n",
        "\n",
        "# 3. check the type of data (change the type as possible)\n",
        "\n",
        "# 4 . check others steps \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3g_Fz0Qpy6S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 4. Déterminer les attributs du modèle et entraîner le modèle"
      ],
      "metadata": {
        "id": "V9y9puabhhqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    1. Choisissez le bon algorithme en fonction de l’objectif de l’apprentissage et de ses besoins en données.\n",
        "    2. Configurer et régler les hyperparamètres pour optimiser les performances, et choisir une méthode d’itération pour arriver aux meilleurs hyperparamètres.\n",
        "    3. Identifier les attributs qui fourniront les meilleurs résultats.\n",
        "    4. Déterminer si l’explicabilité ou l’interprétabilité du modèle est nécessaire.\n",
        "    5. Utiliser plusieurs algorithmes (apprentissage ensembliste) pour améliorer les performances.\n",
        "  \n",
        "    6. Identifier les exigences qu’il faudra respecter pour la mise en production et le déploiement du modèle.\n"
      ],
      "metadata": {
        "id": "uMPKB3tJhtkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2 : Exploration of data \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn \n",
        "# To DO \n",
        "# 1. Faire les visualisations necessaire\n",
        "# 2 . Detecter la variable a expliquer et les variables explicatives (si necessaire)\n",
        "# 3 . Check the correlation between the variables -- interpretation"
      ],
      "metadata": {
        "id": "vnZqSqaK2ykV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 5. Évaluer les performances du modèle et faire des benchmarks"
      ],
      "metadata": {
        "id": "s3oubCa5hu6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    1. Évaluer les modèles en utilisant une approche et un jeu de données de validation.\n",
        "    2. Déterminer les valeurs de la matrice de confusion dans le cadre des problèmes de classification.\n",
        "    3. Identifier des méthodes de validation croisée si cette approche k-fold est utilisée.\n",
        "    4. Affiner les hyperparamètres pour optimiser la performance.\n"
      ],
      "metadata": {
        "id": "uVBixrCGh17p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 3 : choice you modele\n",
        "from sklearn import ....\n",
        "model = \n",
        "# TODO \n",
        "# 1. Appliquer le modele sur vos donnees\n",
        "# 2. check accurancy test data  and others measures --- intrepatation\n",
        "# 3. Save your modele\n",
        "# TODO With the prof \n",
        "# 1. improve your modele  (jeudi )\n",
        "# 2. check the best modele  (jeudi)"
      ],
      "metadata": {
        "id": "RMz6NYO-6MoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exemple To save the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression().fit(X_train,Y_train)\n",
        "import pickle \n",
        "# Save your model in your laptop \n",
        "filename = 'my_best_model.sav' or 'my_best_model.txt'  # file name in my laptop\n",
        "pickle.dump(model,open(filename,'wb') )\n",
        "\n",
        "# read  the modele \n",
        "model_load = pickle.load(open(filename,'rb'))\n",
        "\n",
        "# For tomorow\n",
        "1. install streamlit package\n",
        "2. Create your first application "
      ],
      "metadata": {
        "id": "obp2PjvMBYso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Étape 6. Expérimenter en production et ajuster le modèle"
      ],
      "metadata": {
        "id": "S3viqZMPh8YR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    1. Déployer le modèle \n",
        "    2. Mesurer et  contrôler en permanence ses performances.\n",
        "    \n",
        "\n",
        "La mise en production  du modèle peut aussi  passer par des déploiements dans un environnement cloud. \n",
        "\n",
        "Après le déploiement, il faut considérer :\n",
        " 1. versioning et l’itération des modèles, \n",
        " 2. la supervision et la mise à jour des modèles "
      ],
      "metadata": {
        "id": "3XQ_o-xBiBDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 7. Ajuster le modèle"
      ],
      "metadata": {
        "id": "Nwj6LHMDiPWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. élargissement de l’entraînement pour ajouter de nouvelles fonctionnalités\n",
        "2. Amélioration des performances opérationnelles du modèle \n",
        "      1.  « déviance des modèles » (« model drift ») ,  \n",
        "      2.  « déviance des données » (« data drift »))"
      ],
      "metadata": {
        "id": "xVy2jnCjiYdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AOrUxMQBnHqD"
      }
    }
  ]
}